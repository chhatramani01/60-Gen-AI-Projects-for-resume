# 60 Generative AI Projects for Your Resume

Boost your resume with these amazing Generative AI project ideas, each designed to provide practical experience and highlight your skills with the latest technologies.

Here's a breakdown of each project, relevant tutorials, and code to help you get started and the skills you'll develop.

| **Multimodal LLM Applications** | **LLM Fine-Tuning Projects** | **RAG (Retrieval Augmented Generation) Projects** | **Agentic AI Projects** | **Music and Audio Generation Projects** |
|---|---|---|---|---|
| [Medical Diagnostics App with GPT-4 Vision](#1-medical-diagnostics-app-with-gpt-4-vision) | [Fine Tune Phi-2 Model on Your Dataset](#15-fine-tune-phi-2-model-on-your-dataset) | [End To End Advanced RAG Project using Open Source LLM Models And Groq Inferencing engine](#26-end-to-end-advanced-rag-project-using-open-source-llm-models-and-groq-inferencing-engine) | [AI Agents from Scratch using Open Source AI](#38-ai-agents-from-scratch-using-open-source-ai) | [Text to Song Generation (With Vocals + Music) App using Generative AI](#57-text-to-song-generation-with-vocals--music-app-using-generative-ai) |
| [Visual Question Answering with IDEFICS 9B](#2-visual-question-answering-with-idefics-9b) | [Fine Tune a Multimodal LLM "IDEFICS 9B" for Visual Question Answering](#16-fine-tune-a-multimodal-llm-idefics-9b-for-visual-question-answering) | [RAG Pipeline from Scratch Using OLlama Python & Llama2](#27-rag-pipeline-from-scratch-using-ollama-python--llama2) | [AgentOps Library: Build Your Own AI Agents Monitoring Framework](#39-agentops-library-build-your-own-ai-agents-monitoring-framework) | [Text to Music Generation App using Generative AI](#58-text-to-music-generation-app-using-generative-ai) |
| [AI Voice Assistant App using Multimodal LLM "Llava" and Whisper](#3-ai-voice-assistant-app-using-multimodal-llm-llava-and-whisper) | [Fine Tune Multimodal LLM "Idefics 2" using QLoRA](#17-fine-tune-multimodal-llm-idefics-2-using-qlora) | [RAG Application using Langchain, OpenAI and FAISS](#28-rag-application-using-langchain-openai-and-faiss) | [Build a Multi-Agent AI App from Scratch – no frameworks needed](#40-build-a-multi-agent-ai-app-from-scratch--no-frameworks-needed) | [Generate Music using Text2Music AI Model MusicGen by Meta AI](#59-generate-music-using-text2music-ai-model-musicgen-by-meta-ai) |
| [OCR & VQA with Qwen2-VL](#4-ocr--vqa-with-qwen2-vl) | [Fine Tune Qwen2 VL Model using Llama Factory](#18-fine-tune-qwen2-vl-model-using-llama-factory) | [RAG Application using Langchain Mistral AI and Weviate db](#29-rag-application-using-langchain-mistral-ai-and-weviate-db) | [Autogen AI Agents: AI Debates – Pizza vs. Sushi](#41-autogen-ai-agents-ai-debates--pizza-vs-sushi) | [Clone Any Voice to Generate Music and Speech](#60-clone-any-voice-to-generate-music-and-speech)  |
| [Chat with Video File using Qwen2 VL](#5-chat-with-video-file-using-qwen2-vl) | [Fine-Tuning with ReFT: Create an Emoji LLM for Medical Diagnosis](#19-fine-tuning-with-reft-create-an-emoji-llm-for-medical-diagnosis) | [RAG Application Using OpenSource Framework LlamaIndex and Mistral-AI](#30-rag-application-using-opensource-framework-llamaindex-and-mistral-ai) | [Production Grade AI Agents using LangGraph (Map Reduce Implementation)](#42-production-grade-ai-agents-using-langgraph-map-reduce-implementation) |  |
| [Multimodal RAG with Qwen-2 and ColPali](#6-multimodal-rag-with-qwen-2-and-colpali) | [Fine Tune DeepSeek Model on your Custom Dataset](#20-fine-tune-deepseek-model-on-your-custom-dataset) | [RAG Pipeline Using Haystack and OpenAI](#31-rag-pipeline-using-haystack-and-openai) | [Build an Agentic RAG using Crew AI](#43-build-an-agentic-rag-using-crew-ai) | |
| [Janus 1.3B for Image Generation and RAG](#7-janus-13b-for-image-generation-and-rag) | [GRPO Crash Course: Fine-Tuning DeepSeek for MATH!](#21-grpo-crash-course-fine-tuning-deepseek-for-math) | [RAG Application Using Haystack MistralAI Pinecone & FastAPI](#32-rag-application-using-haystack-mistralai-pinecone--fastapi) | [Build Multi-agent AI system for Investment Risk Analysis](#44-build-multi-agent-ai-system-for-investment-risk-analysis) |  |
| [Chat, Search & Summarize any Video using Vision AI Model](#8-chat-search--summarize-any-video-using-vision-ai-model) | [Fine Tune Llama 3 using ORPO](#22-fine-tune-llama-3-using-orpo) | [End To End Document Q&A RAG App With Gemma And Groq API](#33-end-to-end-document-qa-rag-app-with-gemma-and-groq-api) | [Build a Research Assistant AI Agent using Crew AI](#45-build-a-research-assistant-ai-agent-using-crew-ai) |  |
| [Multimodal AI Model for Radiology Reporting](#9-multimodal-ai-model-for-radiology-reporting) | [Train a Small Language Model for Disease Symptoms](#23-train-a-small-language-model-for-disease-symptoms) | [Building Real-Time RAG Pipeline With Mongodb and Pinecone](#34-building-real-time-rag-pipeline-with-mongodb-and-pinecone) | [ADVANCED Python AI Multi-Agent Project](#46-advanced-python-ai-multi-agent-project) |  |
| [MultiModal RAG Application Using LanceDB and LlamaIndex for Video Processing](#10-multimodal-rag-application-using-lancedb-and-llamaindex-for-video-processing) | [Make LLM Fine Tuning 5x Faster with Unsloth](#24-make-llm-fine-tuning-5x-faster-with-unsloth) | [Chat With Multiple Documents using AstraDB and Langchain](#35-chat-with-multiple-documents-using-astradb-and-langchain) | [Academic Task and Learning Agent System](#47-academic-task-and-learning-agent-system) |  |
| [Multimodal RAG: Chat with PDFs (Images & Tables)](#11-multimodal-rag-chat-with-pdfs-images--tables) | [Multi GPU Fine Tuning of LLM using DeepSpeed and Accelerate](#25-multi-gpu-fine-tuning-of-llm-using-deepspeed-and-accelerate) | [Built Powerful Multimodal RAG using Vertex AI(GCP), AstraDb and Langchain](#36-built-powerful-multimodal-rag-using-vertex-aigcp-astradb-and-langchain) | [ClauseAI](#48-clauseai) |  |
| [MultiModal Summarizer](#12-multimodal-summarizer) |  | [RAG Based Chatbot With Memory(Chat History)](#37-rag-based-chatbot-with-memorychat-history) | [Content Intelligence](#49-content-intelligence) |  |
| [Realtime Multimodal RAG Usecase with Google Gemini-Pro-Vision and Langchain](#13-realtime-multimodal-rag-usecase-with-google-gemini-pro-vision-and-langchain) |  |  | [EU Green Compliance FAQ Bot](#50-eu-green-compliance-faq-bot) |  |
| [End To End Resume Application Tracking System(ATS) Using Google Gemini Pro Vision LIM Model](#14-end-to-end-resume-application-tracking-systemats-using-google-gemini-pro-vision-lim-model) |  |  | [ShopGenie](#51-shopgenie) |  |
|  |  |  | [Weather Disaster Management AI Agent](#52-weather-disaster-management-ai-agent) |  |
|  |  |  | [Career Assistant for Hackathons](#53-career-assistant-for-hackathons) |  |
|  |  |  | [AInsight LangGraph](#54-ainsight-langgraph) |  |
|  |  |  | [Blog Writer Swarm](#55-blog-writer-swarm) |  |
|  |  |  | [Business Meme Generator](#56-business-meme-generator) |  |



---

# Multimodal LLM Applications

## 1. Medical Diagnostics App with GPT-4 Vision

### **Difficulty Level**: 3/5

### **Description**:

This project uses a **multimodal LLM** for medical image analysis to aid in diagnostics. 

### **Skills Gained**:

**Multimodal AI**, medical image analysis, diagnostic applications.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=SzUGQMx0dkw)

- [Code](https://github.com/AIAnytime/Medical-Help-App-using-GPT-4V)

---

## 2. Visual Question Answering with IDEFICS 9B

### **Difficulty Level**: 3/5

### **Description**:

Develop a system that answers questions based on visual input using the **IDEFICS 9B model**. It involves managing visual data and answering questions based on the content of an image.

### **Skills Gained**:

**Visual Question Answering (VQA)**, multimodal models, image understanding.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=hyP1ekLKtiI)

- [Code](https://github.com/AIAnytime/Fine-Tuning-Multimodal-LLM)

- [HF Model](https://huggingface.co/HuggingFaceM4/idefics-9b-instruct)

---

## 3. AI Voice Assistant App using Multimodal LLM "Llava" and Whisper

### **Difficulty Level**: 4/5

### **Description**:

Create a voice assistant that understands voice and visual inputs using **Llava and Whisper**. Combines voice recognition, natural language processing, and visual understanding.

### **Skills Gained**:

**Multimodal AI**, voice recognition, natural language processing, assistant applications.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=77dJJBFPLpY)

- [Code](https://github.com/AIAnytime/Multimodal-AI-App-using-Llava-7B)

---

## 4. OCR & VQA with Qwen2-VL

### **Difficulty Level**: 3/5

### **Description**:

Build a model specialized for **optical character recognition and visual question answering** using the **Qwen2-VL model**. Requires understanding of text extraction from images and answering questions about visual content.

### **Skills Gained**:

**OCR**, VQA, multimodal models, image and text processing.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=lPlJR1xVF8c)

- [Code](https://github.com/AIAnytime/Qwen2-VL-for-OCR-VQA)

- [HF Model](https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct)

---

## 5. Chat with Video File using Qwen2 VL

### **Difficulty Level**: 3/5

### **Description**:

Create an application that allows users to interact with video content by asking questions, leveraging **Qwen2-VL**. Involves processing video data to understand its content.

### **Skills Gained**:

Video understanding, **multimodal AI**, question answering.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=AAgx5p6vmTs)

- [Code](https://github.com/AIAnytime/Chat-with-Video-using-Qwen2-VL)

---

## 6. Multimodal RAG with Qwen-2 and ColPali

### **Difficulty Level**: 4/5

### **Description**:

Combines **multimodal models with Retrieval Augmented Generation** to answer questions based on images, utilizing **Qwen-2 and ColPali**. It involves not only processing images but also integrating them with a retrieval system.

### **Skills Gained**:

**Multimodal RAG**, image and text processing, retrieval systems.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=XfPu044sCRI)

- [Code](https://github.com/AIAnytime/MultiModal-RAG-using-Qwen-2-VL-and-Colpali)

---

## 7. Janus 1.3B for Image Generation and RAG

### **Difficulty Level**: 3/5

### **Description**:

This project uses **Janus 1.3B** for image generation and retrieval-augmented generation tasks. Requires understanding image generation and RAG systems with a smaller language model.

### **Skills Gained**:

Image generation, **RAG**, smaller LLM implementation.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=WWrr8l82ZUU)

- [Code](https://github.com/AIAnytime/Janus-1.3B)

---

## 8. Chat, Search & Summarize any Video using Vision AI Model

### **Difficulty Level**: 2/5

### **Description**:

Focused on video understanding, allowing users to chat, search, and summarize video content. Involves complex processing tasks for video understanding, summarization, and searching.

### **Skills Gained**:

Video processing, summarization, search, **multimodal models**.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=mahUBKhFvRQ)

- [Code](https://github.com/AIAnytime/Qwen-2-VL-Video-Analysis)

---

## 9. Multimodal AI Model for Radiology Reporting

### **Difficulty Level**: 3/5

### **Description**:

Develop a model to automate radiology reporting, integrating image and text data. Requires in depth knowledge of medical imaging and report generation.

### **Skills Gained**:

**Multimodal AI**, medical imaging, report generation.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=Dp4ytX_gE0w)

- [Code](https://github.com/AIAnytime/AI-based-Radiology-Reporting)

---

## 10. MultiModal RAG Application Using LanceDB and LlamaIndex for Video Processing

### **Difficulty Level**: 3/5

### **Description**:

Builds a system that allows for querying of video content using **LanceDB and LlamaIndex**. Involves using these tools for video content processing and retrieval.

### **Skills Gained**:

Video processing, **RAG**, vector databases, LlamaIndex.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=pvrioGzF-6s)

- [Code](https://github.com/sunnysavita10/Generative-AI-Indepth-Basic-to-Advance/blob/main/MultiModal%20RAG/MultiModal_RAG_with_llamaIndex_and_LanceDB.ipynb)

---

## 11. Multimodal RAG: Chat with PDFs (Images & Tables)

### **Difficulty Level**: 2/5

### **Description**:

Build a multimodal Retrieval-Augmented Generation (RAG) pipeline using LangChain and the Unstructured library to query complex PDFs containing various data types, leveraging LLMs like GPT-4 with vision.

### **Skills Gained**:

**Multimodal AI**, data extraction.

### **Resources:**

- [Tutorial](https://www.youtube.com/watch?v=uLrReyH5cu0)

- [Code](https://colab.research.google.com/gist/alejandro-ao/47db0b8b9d00b10a96ab42dd59d90b86/langchain-multimodal.ipynb)

---

## 12. MultiModal Summarizer

### **Difficulty Level**: 2/5

### **Description**:

Create a summarization application that processes different types of media. Requires knowledge of summarization techniques and processing different media types.

### **Skills Gained**:

**Multimodal AI**, summarization, media processing.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=yPr9BDFzau4)

- [Code](https://github.com/sunnysavita10/Generative-AI-Indepth-Basic-to-Advance/blob/main/MultiModal%20RAG/Extract_Image%2CTable%2CText_from_Document_MultiModal_Summrizer_RAG_App.ipynb)

---

## 13. Realtime Multimodal RAG Usecase with Google Gemini-Pro-Vision and Langchain

### **Difficulty Level**: 2/5

### **Description**:

Uses Google's **Gemini Pro Vision with Langchain** for multimodal RAG applications. Requires a deep understanding of both technologies.

### **Skills Gained**:

**Multimodal RAG**, Google Gemini, Langchain.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=1a94Pfn6sIg)

- [Code](https://github.com/sunnysavita10/Generative-AI-Indepth-Basic-to-Advance/blob/90dfa5f67e97466079592ca2294d4fdd06e8ae5e/MultiModal%20RAG/Multimodal_RAG_with_Gemini_Langchain_and_Google_AI_Studio_Yt.ipynb#L283)

---

## 14. End To End Resume Application Tracking System(ATS) Using Google Gemini Pro Vision LIM Model

### **Difficulty Level**: 3/5

### **Description**:

Creates an **ATS** that leverages multimodal models to process resume content, including images and text. This is a full application for understanding and processing resume content for tracking.

### **Skills Gained**:

**Multimodal AI**, resume processing, **ATS development**.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=VZOnp2YpY8Q)

- [Code](https://github.com/krishnaik06/Google-Gemini-Crash-Course/tree/main/atsllm)

---

# LLM Fine-Tuning Projects

---

## 15. Fine Tune Phi-2 Model on Your Dataset

### **Difficulty Level**: 3/5

### **Description**:

Tailor a smaller language model, **Phi-2**, for specific tasks using fine-tuning. Requires understanding of model architectures and training procedures.

### **Skills Gained**:

**LLM fine-tuning**, model adaptation, smaller model optimization.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=eLy74j0KCrY)

- [Code](https://github.com/AIAnytime/Phi-2-Fine-Tuning)

---

## 16. Fine Tune a Multimodal LLM "IDEFICS 9B" for Visual Question Answering

### **Difficulty Level**: 4/5

### **Description**:

Adapts the **IDEFICS 9B** model for visual question answering through fine-tuning. Requires knowledge of fine tuning and Visual Question Answering.

### **Skills Gained**:

**Multimodal fine-tuning**, visual question answering, **LLM customization**.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=usoTCfyQxjU)
- [Code](https://github.com/AIAnytime/Fine-Tuning-Multimodal-LLM)

---

## 17. Fine Tune Multimodal LLM "Idefics 2" using QLoRA

### **Difficulty Level**: 4/5

### **Description**:

Uses **QLoRA** to fine-tune the multimodal **Idefics 2** model. Requires deep understanding of both multimodal models and QLoRA technique.

### **Skills Gained**:

**Multimodal fine-tuning**, **QLoRA**, model optimization.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=8GWmu99-sjA)
- [Code](https://github.com/AIAnytime/Fine-Tune-Multimodal-LLM-Idefics-2)

---

## 18. Fine Tune Qwen2 VL Model using Llama Factory

### **Difficulty Level**: 3/5

### **Description**:

Fine-tunes the **Qwen2 VL model** for specific applications using **Llama Factory**. Requires experience with both the model and the factory tool.

### **Skills Gained**:

**Multimodal fine-tuning**, **Llama Factory**, model adaptation.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=5IqkZ_yms4k)
- [Code](https://github.com/AIAnytime/Qwen2-VL-Fine-Tuning)

---

## 19. Fine-Tuning with ReFT: Create an Emoji LLM for Medical Diagnosis

### **Difficulty Level**: 4/5

### **Description**:

Uses fine-tuning techniques to create a medical diagnosis model that generates emojis. Involves creatively applying fine-tuning to a medical and creative task.

### **Skills Gained**:

**Fine-tuning**, medical diagnosis, creative LLM applications.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=DcFv3APc8E8)
- [Code](https://github.com/AIAnytime/ReFT-Fine-Tuning)

---

## 20. Fine Tune DeepSeek Model on your Custom Dataset

### **Difficulty Level**: 3/5

### **Description**:

Trains the **DeepSeek model** on a custom dataset to tailor it for specific tasks. Requires dataset management skills as well as experience with fine-tuning.

### **Skills Gained**:

**LLM fine-tuning**, model customization, dataset management.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=ZqoZDI0p1aI)
- [Code](https://github.com/AIAnytime/Fine-Tune-DeepSeek)

---

## 21. GRPO Crash Course: Fine-Tuning DeepSeek for MATH!

### **Difficulty Level**: 1/5

### **Description**:

Optimizes the **DeepSeek model** for math-related tasks using **GRPO**. Requires an understanding of math with LLMs and group optimization techniques.

### **Skills Gained**:

**LLM fine-tuning**, **GRPO**, mathematical reasoning with LLMs.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=8bIeSJ1WnC0)
- [Code](https://github.com/AIAnytime/GRPO-explained-like-ELI5)

---

## 22. Fine Tune Llama 3 using ORPO

### **Difficulty Level**: 3/5

### **Description**:

Optimizes the **Llama 3 model** using the **ORPO technique**. Requires a strong understanding of fine tuning.

### **Skills Gained**:

**LLM fine-tuning**, **ORPO**, model optimization.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=nPIGVaYPQAg)

- [Code](https://github.com/AIAnytime/Llama-3-ORPO-Fine-Tuning)

---

## 23. Train a Small Language Model for Disease Symptoms

### **Difficulty Level**: 3/5

### **Description**:

Creates a model specifically for identifying disease symptoms. Involves medical knowledge with a fine-tuned language model.

### **Skills Gained**:

**LLM fine-tuning**, medical applications, symptom identification.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=1ILVm4IeNY8)

- [Code](https://github.com/AIAnytime/Training-Small-Language-Model)

---

## 24. Make LLM Fine Tuning 5x Faster with Unsloth

### **Difficulty Level**: 2/5

### **Description**:

Improves **LLM fine-tuning speeds** by using **Unsloth**. Requires an understanding of optimization techniques for fine tuning.

### **Skills Gained**:

**LLM fine-tuning**, performance optimization, **Unsloth**.

### **Resources**:

- [Tutorial](https://www.youtube.com/watch?v=sIFokbuATX4)

- [Code](https://github.com/AIAnytime/Unsloth-Fine-Tuning)

---

## 25. Multi GPU Fine Tuning of LLM using DeepSpeed and Accelerate

### **Difficulty Level**: 3/5

### **Description**:

Fine-tunes large language models using mult
